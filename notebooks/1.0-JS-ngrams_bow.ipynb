{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Reimplementation of the BoW (with n-grams) baseline methods presented in and evaluated against the annotations from: \n",
    "> Gehrmann, Sebastian, et al. \"Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives.\" PloS one 13.2 (2018): e0192360."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported packages\n",
    "import multiprocessing\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# arrays and dataframes\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# plotting\n",
    "import matplotlib \n",
    "matplotlib.use('Agg') # server\n",
    "try:\n",
    "    get_ipython\n",
    "    # jupyter notebook\n",
    "    %matplotlib inline \n",
    "except:\n",
    "    pass\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom modules\n",
    "import context # set search path to one level up\n",
    "from src import evaluation  # method for evaluation of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and parameters\n",
    "# filenames\n",
    "input_filename = '../data/raw/annotations.csv'\n",
    "results_filename = '../reports/ngrams_bow_results.csv'\n",
    "plot_filename_1 = '../reports/ngrams_bow_boxplot_1.png'\n",
    "plot_filename_2 = '../reports/ngrams_bow_boxplot_2.png'\n",
    "\n",
    "# number of splits and repeats for cross validation\n",
    "n_splits = 5\n",
    "n_repeats = 10\n",
    "# n_repeats = 1  # for testing\n",
    "\n",
    "# number of workers\n",
    "n_workers=multiprocessing.cpu_count()\n",
    "# n_workers = 1  # for testing\n",
    "\n",
    "# keep the conditions for which results are reported in the publication\n",
    "conditions = [  \n",
    "#     'cohort',\n",
    "    'Obesity',\n",
    "#     'Non.Adherence',\n",
    "#     'Developmental.Delay.Retardation',\n",
    "    'Advanced.Heart.Disease', \n",
    "    'Advanced.Lung.Disease', \n",
    "    'Schizophrenia.and.other.Psychiatric.Disorders',\n",
    "    'Alcohol.Abuse', \n",
    "    'Other.Substance.Abuse',\n",
    "    'Chronic.Pain.Fibromyalgia', \n",
    "    'Chronic.Neurological.Dystrophies', \n",
    "    'Advanced.Cancer',\n",
    "    'Depression',\n",
    "#     'Dementia',\n",
    "#     'Unsure',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and parse csv file\n",
    "data = pandas.read_csv(input_filename)\n",
    "# data = data[0:100]  # for testing\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign and clean the X and y variables\n",
    "# X: the clinical notes\n",
    "X_df = data.filter(items=['text'])\n",
    "X = X_df['text']\n",
    "# groups: the subject ids\n",
    "# used in order to ensure that \n",
    "# \"patientsâ€™ notes stay within the set, so that all discharge notes in the \n",
    "# test set are from patients not previously seen by the model.\" Gehrmann17.\n",
    "groups_df = data.filter(items=['subject.id']) \n",
    "groups = groups_df.as_matrix()\n",
    "# y: the annotated classes\n",
    "y_df = data.filter(items=conditions) # filter the conditions\n",
    "y = y_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_df.shape, groups_df.shape, y_df.shape)\n",
    "print(X.shape, groups.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of classifiers (sklearn estimators)\n",
    "classifiers = collections.OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    pattern = r'[^\\w]+'  # match any non-alphanumerical character\n",
    "    repl = r' '  # replace with space\n",
    "    temp_text = re.sub(pattern, repl, text)\n",
    "    return temp_text.lower().split(' ')  # lower-case and split on space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_models = [\n",
    "    ('logistic_regression', LogisticRegression(random_state=0)),\n",
    "    (\"random_forest\", RandomForestClassifier(random_state=0)),\n",
    "    (\"naive_bayes\", MultinomialNB()),\n",
    "    (\"svm_linear\", SVC(kernel=\"linear\", random_state=0, probability=True)),\n",
    "    (\"gradient_boosting\", GradientBoostingClassifier(random_state=0)),\n",
    "]\n",
    "\n",
    "# 1-gram, 1-gram + 2-gram ..., 1-gram to 5-gram (word grams) -> BoW\n",
    "representation_models = [('{n}gram_bow'.format(n=i), CountVectorizer(ngram_range=(1, i), tokenizer=tokenizer)) for i in range(1, 5+1)]\n",
    "\n",
    "# cross product of representation models and prediction models\n",
    "# save to classifiers as pipelines of rep. model into pred. model\n",
    "for rep_model, pred_model in itertools.product(representation_models, prediction_models):\n",
    "    classifiers.update({  # add this classifier to classifiers dictionary\n",
    "        '{rep_model}_{pred_model}'.format(rep_model=rep_model[0], pred_model=pred_model[0]):  # classifier name\n",
    "        Pipeline([rep_model, pred_model]),  # concatenate representation model with prediction model in a pipeline\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation.run_evaluation(X=X, \n",
    "                                    y=y, \n",
    "                                    groups=groups,\n",
    "                                    conditions=conditions,\n",
    "                                    classifiers=classifiers,\n",
    "                                    n_splits=n_splits, \n",
    "                                    n_repeats=n_repeats, \n",
    "                                    n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results        \n",
    "results_df = pandas.DataFrame(results)\n",
    "results_df.to_csv(results_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load results for plotting\n",
    "# import pandas\n",
    "# results = pandas.read_csv('output/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "axs = results_df.groupby('name').boxplot(column='AUROC', by='condition', rot=90, figsize=(10,10))\n",
    "for ax in axs:\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "plt.savefig(plot_filename_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "axs = results_df.groupby('condition').boxplot(column='AUROC', by='name', rot=90, figsize=(10,10))\n",
    "for ax in axs:\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "plt.savefig(plot_filename_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
